{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "      Id                                             Prompt  \\\n",
      "0  11527  [INST] You are an AI assistant that helps peop...   \n",
      "1   7322  [INST] You are an AI assistant. You will be gi...   \n",
      "2  11742  [INST] You are an AI assistant. You will be gi...   \n",
      "3  20928  [INST] You are an AI assistant. User will you ...   \n",
      "4  25830  [INST] You are an AI assistant. User will you ...   \n",
      "\n",
      "                                              Answer  Target  \n",
      "0  Step-by-step reasoning process:\\n1. Randy spen...       0  \n",
      "1  What is the temperature at which hypothermia b...       0  \n",
      "2  Answer: c) No. \\n\\nThe hypothesis is false bec...       0  \n",
      "3                                         Prismatoid       0  \n",
      "4                                             Case B       0  \n",
      "\n",
      "Test Data:\n",
      "      Id                                             Prompt  \\\n",
      "0  20568  [INST] You are an AI assistant. You will be gi...   \n",
      "1  17686  question:Question: This article: According to ...   \n",
      "2  13035  [INST] You are an AI assistant. Provide a deta...   \n",
      "3  22646  [INST] You are an AI assistant. User will you ...   \n",
      "4   5535  [INST] You are an AI assistant. You will be gi...   \n",
      "\n",
      "                                              Answer  \n",
      "0  London Irish lost to Grenoble 21-6 in the Euro...  \n",
      "1                                              10.2%  \n",
      "2                                       Can't answer  \n",
      "3  'Ahora, por lo tanto, no eres tú quien me enví...  \n",
      "4  c). can decrease blood pressure \\n d). can dec...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load training data\n",
    "train_data = pd.read_csv('train.csv')  # replace 'train.csv' with your actual file path\n",
    "prompts_train = train_data['Prompt'].tolist()\n",
    "answers_train = train_data['Answer'].tolist()\n",
    "labels_train = train_data['Target'].tolist()  # Target is present in train.csv\n",
    "\n",
    "# Load test data (this does not have 'Target')\n",
    "test_data = pd.read_csv('test.csv')  # replace 'test.csv' with your actual file path\n",
    "prompts_test = test_data['Prompt'].tolist()\n",
    "answers_test = test_data['Answer'].tolist()\n",
    "\n",
    "# Check the first few rows of both datasets\n",
    "print(\"Training Data:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nTest Data:\")\n",
    "print(test_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model to evaluation mode (disable gradient calculation)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Labels shape: (16668,)\n",
      "Training data shape: (13334, 1536)\n",
      "Validation data shape: (3334, 1536)\n",
      "Training labels shape: (13334,)\n",
      "Validation labels shape: (3334,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data (train.csv)\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Load the precomputed combined embeddings\n",
    "combined_embeddings_train = np.load('combined_embeddings_train.npy')\n",
    "\n",
    "# Get labels (Targets) from your dataset\n",
    "labels_train = data['Target'].tolist()\n",
    "\n",
    "# Filter labels to match filtered prompts and answers\n",
    "filtered_prompts = data['Prompt'].dropna().str.strip().tolist()\n",
    "filtered_answers = data['Answer'].dropna().str.strip().tolist()\n",
    "\n",
    "filtered_labels = []\n",
    "for i, (prompt, answer) in enumerate(zip(filtered_prompts, filtered_answers)):\n",
    "    if isinstance(prompt, str) and isinstance(answer, str) and prompt and answer:\n",
    "        filtered_labels.append(labels_train[i])\n",
    "\n",
    "# Convert the filtered labels to a NumPy array\n",
    "labels_train_np = np.array(filtered_labels)\n",
    "print(\"Filtered Labels shape:\", labels_train_np.shape)\n",
    "\n",
    "# Split the combined embeddings and labels into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(combined_embeddings_train, labels_train_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Training labels shape:\", y_train.shape)\n",
    "print(\"Validation labels shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Logistic Regression classifier...\n",
      "Validation Accuracy: 94.69%\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      0.99      0.97      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "clf = LogisticRegression(max_iter=1000)  # Increase max_iter to ensure convergence\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Logistic Regression classifier...\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Random Forest classifier...\n",
      "Validation Accuracy (Random Forest): 95.29%\n",
      "Classification Report (Random Forest):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.98      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Random Forest classifier...\")\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_rf = rf_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_val, y_pred_rf)\n",
    "print(f\"Validation Accuracy (Random Forest): {accuracy_rf * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Random Forest):\")\n",
    "print(classification_report(y_val, y_pred_rf, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the SVM classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (SVM): 63.41%\n",
      "Classification Report (SVM):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      0.65      0.77      3177\n",
      "   Hallucination       0.04      0.31      0.07       157\n",
      "\n",
      "        accuracy                           0.63      3334\n",
      "       macro avg       0.50      0.48      0.42      3334\n",
      "    weighted avg       0.91      0.63      0.74      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Support Vector Machine model\n",
    "svm_clf = SVC(kernel='linear', max_iter=1000, random_state=42)  # Use a linear kernel and set max_iter for convergence\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the SVM classifier...\")\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_val, y_pred_svm)\n",
    "print(f\"Validation Accuracy (SVM): {accuracy_svm * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (SVM):\")\n",
    "print(classification_report(y_val, y_pred_svm, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the k-Nearest Neighbors classifier...\n",
      "Validation Accuracy (k-NN): 95.17%\n",
      "Classification Report (k-NN):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.98      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the k-Nearest Neighbors model\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)  # Set k (number of neighbors) to 5\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the k-Nearest Neighbors classifier...\")\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_knn = knn_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_val, y_pred_knn)\n",
    "print(f\"Validation Accuracy (k-NN): {accuracy_knn * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (k-NN):\")\n",
    "print(classification_report(y_val, y_pred_knn, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Decision Tree classifier...\n",
      "Validation Accuracy (Decision Tree): 88.78%\n",
      "Classification Report (Decision Tree):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      0.93      0.94      3177\n",
      "   Hallucination       0.06      0.09      0.07       157\n",
      "\n",
      "        accuracy                           0.89      3334\n",
      "       macro avg       0.51      0.51      0.50      3334\n",
      "    weighted avg       0.91      0.89      0.90      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Decision Tree model\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Decision Tree classifier...\")\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_dt = dt_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_val, y_pred_dt)\n",
    "print(f\"Validation Accuracy (Decision Tree): {accuracy_dt * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Decision Tree):\")\n",
    "print(classification_report(y_val, y_pred_dt, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Naive Bayes classifier...\n",
      "Validation Accuracy (Naive Bayes): 70.94%\n",
      "Classification Report (Naive Bayes):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.96      0.73      0.83      3177\n",
      "   Hallucination       0.06      0.34      0.10       157\n",
      "\n",
      "        accuracy                           0.71      3334\n",
      "       macro avg       0.51      0.54      0.46      3334\n",
      "    weighted avg       0.92      0.71      0.79      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Naive Bayes model\n",
    "nb_clf = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Naive Bayes classifier...\")\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_nb = nb_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_nb = accuracy_score(y_val, y_pred_nb)\n",
    "print(f\"Validation Accuracy (Naive Bayes): {accuracy_nb * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Naive Bayes):\")\n",
    "print(classification_report(y_val, y_pred_nb, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Gradient Boosting classifier...\n",
      "Validation Accuracy (Gradient Boosting): 95.11%\n",
      "Classification Report (Gradient Boosting):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.97      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "gb_clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Gradient Boosting classifier...\")\n",
    "gb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_gb = gb_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_gb = accuracy_score(y_val, y_pred_gb)\n",
    "print(f\"Validation Accuracy (Gradient Boosting): {accuracy_gb * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Gradient Boosting):\")\n",
    "print(classification_report(y_val, y_pred_gb, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the AdaBoost classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (AdaBoost): 95.23%\n",
      "Classification Report (AdaBoost):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.98      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the AdaBoost model\n",
    "ada_clf = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the AdaBoost classifier...\")\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_ada = ada_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_ada = accuracy_score(y_val, y_pred_ada)\n",
    "print(f\"Validation Accuracy (AdaBoost): {accuracy_ada * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (AdaBoost):\")\n",
    "print(classification_report(y_val, y_pred_ada, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the MLP classifier...\n",
      "Validation Accuracy (MLP): 93.43%\n",
      "Classification Report (MLP):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      0.98      0.97      3177\n",
      "   Hallucination       0.06      0.03      0.04       157\n",
      "\n",
      "        accuracy                           0.93      3334\n",
      "       macro avg       0.51      0.50      0.50      3334\n",
      "    weighted avg       0.91      0.93      0.92      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the MLP (Neural Network) model\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=300, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the MLP classifier...\")\n",
    "mlp_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_mlp = mlp_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_mlp = accuracy_score(y_val, y_pred_mlp)\n",
    "print(f\"Validation Accuracy (MLP): {accuracy_mlp * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (MLP):\")\n",
    "print(classification_report(y_val, y_pred_mlp, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the LDA classifier...\n",
      "Validation Accuracy (LDA): 93.91%\n",
      "Classification Report (LDA):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      0.98      0.97      3177\n",
      "   Hallucination       0.06      0.02      0.03       157\n",
      "\n",
      "        accuracy                           0.94      3334\n",
      "       macro avg       0.51      0.50      0.50      3334\n",
      "    weighted avg       0.91      0.94      0.92      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Linear Discriminant Analysis model\n",
    "lda_clf = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the LDA classifier...\")\n",
    "lda_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_lda = lda_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lda = accuracy_score(y_val, y_pred_lda)\n",
    "print(f\"Validation Accuracy (LDA): {accuracy_lda * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (LDA):\")\n",
    "print(classification_report(y_val, y_pred_lda, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the QDA classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\discriminant_analysis.py:935: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy (QDA): 95.29%\n",
      "Classification Report (QDA):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.98      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Quadratic Discriminant Analysis model\n",
    "qda_clf = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the QDA classifier...\")\n",
    "qda_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_qda = qda_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_qda = accuracy_score(y_val, y_pred_qda)\n",
    "print(f\"Validation Accuracy (QDA): {accuracy_qda * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (QDA):\")\n",
    "print(classification_report(y_val, y_pred_qda, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Extra Trees classifier...\n",
      "Validation Accuracy (Extra Trees): 95.29%\n",
      "Classification Report (Extra Trees):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.98      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Extra Trees model\n",
    "et_clf = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Extra Trees classifier...\")\n",
    "et_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_et = et_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_et = accuracy_score(y_val, y_pred_et)\n",
    "print(f\"Validation Accuracy (Extra Trees): {accuracy_et * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Extra Trees):\")\n",
    "print(classification_report(y_val, y_pred_et, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Bagging classifier...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train the classifier on the training set\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining the Bagging classifier...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mbagging_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Predict on the validation set\u001b[39;00m\n\u001b[0;32m     16\u001b[0m y_pred_bagging \u001b[38;5;241m=\u001b[39m bagging_clf\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_bagging.py:334\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    327\u001b[0m     X,\n\u001b[0;32m    328\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    333\u001b[0m )\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_bagging.py:469\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    466\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 469\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    488\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_bagging.py:145\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[0;32m    142\u001b[0m         curr_sample_weight[not_indices_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    144\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 145\u001b[0m     \u001b[43mestimator_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the base classifier (e.g., DecisionTree)\n",
    "base_clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize the Bagging model using the base classifier\n",
    "bagging_clf = BaggingClassifier(base_clf, n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Bagging classifier...\")\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_bagging = bagging_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_bagging = accuracy_score(y_val, y_pred_bagging)\n",
    "print(f\"Validation Accuracy (Bagging): {accuracy_bagging * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Bagging):\")\n",
    "print(classification_report(y_val, y_pred_bagging, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Ridge Classifier...\n",
      "Validation Accuracy (Ridge Classifier): 95.29%\n",
      "Classification Report (Ridge Classifier):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.98      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Ridge Classifier model\n",
    "ridge_clf = RidgeClassifier(alpha=1.0)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Ridge Classifier...\")\n",
    "ridge_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_ridge = ridge_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_ridge = accuracy_score(y_val, y_pred_ridge)\n",
    "print(f\"Validation Accuracy (Ridge Classifier): {accuracy_ridge * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Ridge Classifier):\")\n",
    "print(classification_report(y_val, y_pred_ridge, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the Perceptron classifier...\n",
      "Validation Accuracy (Perceptron): 95.11%\n",
      "Classification Report (Perceptron):\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Hallucination       0.95      1.00      0.97      3177\n",
      "   Hallucination       0.00      0.00      0.00       157\n",
      "\n",
      "        accuracy                           0.95      3334\n",
      "       macro avg       0.48      0.50      0.49      3334\n",
      "    weighted avg       0.91      0.95      0.93      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Perceptron model\n",
    "perceptron_clf = Perceptron(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "print(\"Training the Perceptron classifier...\")\n",
    "perceptron_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_perceptron = perceptron_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_perceptron = accuracy_score(y_val, y_pred_perceptron)\n",
    "print(f\"Validation Accuracy (Perceptron): {accuracy_perceptron * 100:.2f}%\")\n",
    "\n",
    "# Get a detailed classification report (precision, recall, F1-score)\n",
    "print(\"Classification Report (Perceptron):\")\n",
    "print(classification_report(y_val, y_pred_perceptron, target_names=['No Hallucination', 'Hallucination']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
