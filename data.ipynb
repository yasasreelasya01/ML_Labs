{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_dataset(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "data = load_dataset('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_missing_values(df, column):\n",
    "    return df.dropna(subset=[column])\n",
    "\n",
    "# Clean the dataset by removing rows with missing 'Answer'\n",
    "data_cleaned = clean_missing_values(data, \"Answer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "Id        0\n",
      "Prompt    0\n",
      "Answer    0\n",
      "Target    0\n",
      "dtype: int64\n",
      "\n",
      "Dataset shape: (16668, 4)\n"
     ]
    }
   ],
   "source": [
    "def verify_cleaning(df):\n",
    "    \"\"\"Check for any remaining missing values and print dataset shape.\"\"\"\n",
    "    print(\"Missing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\nDataset shape:\", df.shape)\n",
    "\n",
    "# Verify cleaning\n",
    "verify_cleaning(data_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def compute_bert_embeddings(prompt, answer):\n",
    "    \"\"\"Generate BERT embeddings for the concatenated prompt and answer.\"\"\"\n",
    "    # Combine prompt and answer\n",
    "    text = f\"{prompt} [SEP] {answer}\"\n",
    "    \n",
    "    # Tokenize and create input tensors\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512, padding='max_length')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use the CLS token's output as the embedding\n",
    "    return outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m bert_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_cleaned\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(df, model, tokenizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m----> 7\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_bert_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrompt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAnswer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mappend(embedding)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings)\n",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m, in \u001b[0;36mcompute_bert_embeddings\u001b[1;34m(prompt, answer)\u001b[0m\n\u001b[0;32m     14\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Use the CLS token's output as the embedding\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:988\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    979\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m    981\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m    982\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    983\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    986\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[0;32m    987\u001b[0m )\n\u001b[1;32m--> 988\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1000\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:582\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    571\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    572\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    573\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         output_attentions,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:514\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    511\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    512\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 514\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    519\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\pytorch_utils.py:237\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:527\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m    526\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m--> 527\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[1;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 439\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    440\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m    441\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_embeddings(df, model, tokenizer):\n",
    "    \"\"\"Apply the embedding function to the entire dataset.\"\"\"\n",
    "    embeddings = []\n",
    "    for _, row in df.iterrows():\n",
    "        embedding = compute_bert_embeddings(row['Prompt'], row['Answer'])\n",
    "        embeddings.append(embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate embeddings\n",
    "bert_embeddings = generate_embeddings(data_cleaned, model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m     np\u001b[38;5;241m.\u001b[39msave(file_name, embeddings)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Save the BERT embeddings\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m save_embeddings(\u001b[43mbert_embeddings\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert_embeddings.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bert_embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "def save_embeddings(embeddings, file_name):\n",
    "    \"\"\"Save embeddings to a .npy file.\"\"\"\n",
    "    np.save(file_name, embeddings)\n",
    "\n",
    "# Save the BERT embeddings\n",
    "save_embeddings(bert_embeddings, 'bert_embeddings.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing data split successfully.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the saved embeddings\n",
    "import numpy as np\n",
    "saved_embeddings_path = \"bert_embeddings.npy\"\n",
    "bert_embeddings = np.load(saved_embeddings_path)\n",
    "\n",
    "# Assuming 'data_cleaned' is a DataFrame and 'Target' is a column in it\n",
    "# Replace 'data_cleaned['Target']' with your actual target variable if needed\n",
    "target = data_cleaned['Target'].values  # Ensure this is a NumPy array\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(bert_embeddings, target, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training and testing data split successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"Train a Logistic Regression model.\"\"\"\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the logistic regression model\n",
    "logistic_model = train_logistic_regression(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94841\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95626   0.99118   0.97341      3176\n",
      "           1    0.33333   0.08861   0.14000       158\n",
      "\n",
      "    accuracy                        0.94841      3334\n",
      "   macro avg    0.64480   0.53990   0.55670      3334\n",
      "weighted avg    0.92674   0.94841   0.93391      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluate the model's performance on test data.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", round(accuracy, 5))  # Display accuracy with 5 decimal places\n",
    "    \n",
    "    # Get the classification report and format the precision and recall to 5 decimal places\n",
    "    report = classification_report(y_test, y_pred, digits=5)\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "    \n",
    "    return accuracy\n",
    "# Evaluate the logistic regression model\n",
    "logistic_accuracy = evaluate_model(logistic_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(X_train, y_train, n_estimators=100, random_state=42):\n",
    "    \"\"\"Train a Random Forest Classifier.\"\"\"\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Random Forest model\n",
    "random_forest_model = train_random_forest(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95501\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95490   1.00000   0.97693      3176\n",
      "           1    1.00000   0.05063   0.09639       158\n",
      "\n",
      "    accuracy                        0.95501      3334\n",
      "   macro avg    0.97745   0.52532   0.53666      3334\n",
      "weighted avg    0.95704   0.95501   0.93520      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Random Forest model\n",
    "random_forest_accuracy = evaluate_model(random_forest_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\core.py:158: UserWarning: [22:31:01] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def train_xgboost(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train an XGBoost Classifier.\"\"\"\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the XGBoost model\n",
    "xgboost_model = train_xgboost(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95471\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95571   0.99874   0.97675      3176\n",
      "           1    0.73333   0.06962   0.12717       158\n",
      "\n",
      "    accuracy                        0.95471      3334\n",
      "   macro avg    0.84452   0.53418   0.55196      3334\n",
      "weighted avg    0.94517   0.95471   0.93649      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the XGBoost model\n",
    "xgboost_accuracy = evaluate_model(xgboost_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_decision_tree(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train a Decision Tree Classifier.\"\"\"\n",
    "    model = DecisionTreeClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Decision Tree model\n",
    "decision_tree_model = train_decision_tree(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90792\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95992   0.94270   0.95123      3176\n",
      "           1    0.15349   0.20886   0.17694       158\n",
      "\n",
      "    accuracy                        0.90792      3334\n",
      "   macro avg    0.55671   0.57578   0.56409      3334\n",
      "weighted avg    0.92171   0.90792   0.91454      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Decision Tree model\n",
    "decision_tree_accuracy = evaluate_model(decision_tree_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_adaboost(X_train, y_train, n_estimators=50, random_state=42):\n",
    "    \"\"\"Train an AdaBoost Classifier.\"\"\"\n",
    "    model = AdaBoostClassifier(n_estimators=n_estimators, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the AdaBoost model\n",
    "adaboost_model = train_adaboost(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95021\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95496   0.99465   0.97440      3176\n",
      "           1    0.34615   0.05696   0.09783       158\n",
      "\n",
      "    accuracy                        0.95021      3334\n",
      "   macro avg    0.65056   0.52580   0.53611      3334\n",
      "weighted avg    0.92611   0.95021   0.93286      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the AdaBoost model\n",
    "adaboost_accuracy = evaluate_model(adaboost_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(X_train, y_train):\n",
    "    \"\"\"Train a Gaussian Naive Bayes Classifier.\"\"\"\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "naive_bayes_model = train_naive_bayes(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67876\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97218   0.68230   0.80185      3176\n",
      "           1    0.08688   0.60759   0.15202       158\n",
      "\n",
      "    accuracy                        0.67876      3334\n",
      "   macro avg    0.52953   0.64495   0.47693      3334\n",
      "weighted avg    0.93023   0.67876   0.77105      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Naive Bayes model\n",
    "naive_bayes_accuracy = evaluate_model(naive_bayes_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(X_train, y_train, kernel='linear', random_state=42):\n",
    "    \"\"\"Train a Support Vector Machine (SVM) Classifier.\"\"\"\n",
    "    model = SVC(kernel=kernel, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the SVM model\n",
    "svm_model = train_svm(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95411\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95404   1.00000   0.97648      3176\n",
      "           1    1.00000   0.03165   0.06135       158\n",
      "\n",
      "    accuracy                        0.95411      3334\n",
      "   macro avg    0.97702   0.51582   0.51891      3334\n",
      "weighted avg    0.95622   0.95411   0.93311      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the SVM model\n",
    "svm_accuracy = evaluate_model(svm_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X_train, y_train, max_iter=1000, random_state=42):\n",
    "    \"\"\"Train a Perceptron Classifier.\"\"\"\n",
    "    model = Perceptron(max_iter=max_iter, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Perceptron model\n",
    "perceptron_model = train_perceptron(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95171\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95284   0.99874   0.97525      3176\n",
      "           1    0.20000   0.00633   0.01227       158\n",
      "\n",
      "    accuracy                        0.95171      3334\n",
      "   macro avg    0.57642   0.50253   0.49376      3334\n",
      "weighted avg    0.91716   0.95171   0.92961      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Perceptron model\n",
    "perceptron_accuracy = evaluate_model(perceptron_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(X_train, y_train, hidden_layer_sizes=(100,), max_iter=300, random_state=42):\n",
    "    \"\"\"Train a Multi-Layer Perceptron (MLP) Classifier.\"\"\"\n",
    "    model = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=max_iter, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_model = train_mlp(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94991\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.96023   0.98835   0.97409      3176\n",
      "           1    0.43077   0.17722   0.25112       158\n",
      "\n",
      "    accuracy                        0.94991      3334\n",
      "   macro avg    0.69550   0.58278   0.61260      3334\n",
      "weighted avg    0.93514   0.94991   0.93983      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the MLP model\n",
    "mlp_accuracy = evaluate_model(mlp_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_knn(X_train, y_train, n_neighbors=5, metric='minkowski', p=2):\n",
    "    \"\"\"Train a k-Nearest Neighbors (kNN) Classifier.\"\"\"\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric, p=p)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the kNN model\n",
    "knn_model = train_knn(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95231\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95643   0.99528   0.97547      3176\n",
      "           1    0.48276   0.08861   0.14973       158\n",
      "\n",
      "    accuracy                        0.95231      3334\n",
      "   macro avg    0.71959   0.54194   0.56260      3334\n",
      "weighted avg    0.93398   0.95231   0.93633      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the kNN model\n",
    "knn_accuracy = evaluate_model(knn_model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X_train, y_train):\n",
    "    \"\"\"Apply SMOTE to balance the data.\"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "# Apply SMOTE to balance the training data\n",
    "X_train_resampled, y_train_resampled = apply_smote(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81074\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.97217   0.82494   0.89252      3176\n",
      "           1    0.12989   0.52532   0.20828       158\n",
      "\n",
      "    accuracy                        0.81074      3334\n",
      "   macro avg    0.55103   0.67513   0.55040      3334\n",
      "weighted avg    0.93225   0.81074   0.86010      3334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain Logistic Regression on resampled data\n",
    "logistic_model_resampled = train_logistic_regression(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate the Logistic Regression model on resampled data\n",
    "logistic_accuracy_resampled = evaluate_model(logistic_model_resampled, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X_resampled, y_resampled, test_size=0.2, random_state=42):\n",
    "    \"\"\"Split the resampled data into training and test sets.\"\"\"\n",
    "    X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = train_test_split(\n",
    "        X_resampled, y_resampled, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    return X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled\n",
    "\n",
    "# Split the resampled data\n",
    "X_train_resampled, X_test_resampled, y_train_resampled, y_test_resampled = split_data(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86142\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90451   0.81311   0.85638      2563\n",
      "           1    0.82518   0.91133   0.86612      2481\n",
      "\n",
      "    accuracy                        0.86142      5044\n",
      "   macro avg    0.86485   0.86222   0.86125      5044\n",
      "weighted avg    0.86549   0.86142   0.86117      5044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrain Logistic Regression on the resampled data\n",
    "logistic_model_resampled = train_logistic_regression(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate Logistic Regression model on the resampled test set\n",
    "logistic_accuracy_resampled = evaluate_model(logistic_model_resampled, X_test_resampled, y_test_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_random_forest(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train a Random Forest Classifier.\"\"\"\n",
    "    model = RandomForestClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Random Forest model on resampled data\n",
    "rf_model_resampled = train_random_forest(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99108\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99103   0.99142   0.99122      2563\n",
      "           1    0.99113   0.99073   0.99093      2481\n",
      "\n",
      "    accuracy                        0.99108      5044\n",
      "   macro avg    0.99108   0.99107   0.99108      5044\n",
      "weighted avg    0.99108   0.99108   0.99108      5044\n",
      "\n",
      "Random Forest Accuracy on SMOTE data: 0.9910785091197463\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Random Forest model on the resampled test data\n",
    "rf_accuracy_resampled = evaluate_model(rf_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"Random Forest Accuracy on SMOTE data: {rf_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def train_xgboost(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train an XGBoost Classifier.\"\"\"\n",
    "    model = xgb.XGBClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the XGBoost model on resampled data\n",
    "xgboost_model_resampled = train_xgboost(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98454\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99800   0.97152   0.98458      2563\n",
      "           1    0.97136   0.99798   0.98449      2481\n",
      "\n",
      "    accuracy                        0.98454      5044\n",
      "   macro avg    0.98468   0.98475   0.98454      5044\n",
      "weighted avg    0.98490   0.98454   0.98454      5044\n",
      "\n",
      "XGBoost Accuracy on SMOTE data: 0.9845360824742269\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the XGBoost model on the resampled test data\n",
    "xgboost_accuracy_resampled = evaluate_model(xgboost_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"XGBoost Accuracy on SMOTE data: {xgboost_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def train_decision_tree(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train a Decision Tree Classifier.\"\"\"\n",
    "    model = DecisionTreeClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Decision Tree model on resampled data\n",
    "decision_tree_model_resampled = train_decision_tree(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88204\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.91137   0.85057   0.87992      2563\n",
      "           1    0.85558   0.91455   0.88408      2481\n",
      "\n",
      "    accuracy                        0.88204      5044\n",
      "   macro avg    0.88348   0.88256   0.88200      5044\n",
      "weighted avg    0.88393   0.88204   0.88197      5044\n",
      "\n",
      "Decision Tree Accuracy on SMOTE data: 0.8820380650277557\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Decision Tree model on the resampled test data\n",
    "decision_tree_accuracy_resampled = evaluate_model(decision_tree_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"Decision Tree Accuracy on SMOTE data: {decision_tree_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yasas\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "def train_adaboost(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train an AdaBoost Classifier.\"\"\"\n",
    "    model = AdaBoostClassifier(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the AdaBoost model on resampled data\n",
    "adaboost_model_resampled = train_adaboost(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79342\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81155   0.77292   0.79177      2563\n",
      "           1    0.77641   0.81459   0.79504      2481\n",
      "\n",
      "    accuracy                        0.79342      5044\n",
      "   macro avg    0.79398   0.79376   0.79340      5044\n",
      "weighted avg    0.79427   0.79342   0.79338      5044\n",
      "\n",
      "AdaBoost Accuracy on SMOTE data: 0.7934179222839016\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the AdaBoost model on the resampled test data\n",
    "adaboost_accuracy_resampled = evaluate_model(adaboost_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"AdaBoost Accuracy on SMOTE data: {adaboost_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    \"\"\"Train a Naive Bayes Classifier.\"\"\"\n",
    "    model = GaussianNB()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Naive Bayes model on resampled data\n",
    "naive_bayes_model_resampled = train_naive_bayes(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.66872\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.69459   0.62115   0.65582      2563\n",
      "           1    0.64717   0.71786   0.68068      2481\n",
      "\n",
      "    accuracy                        0.66872      5044\n",
      "   macro avg    0.67088   0.66950   0.66825      5044\n",
      "weighted avg    0.67126   0.66872   0.66805      5044\n",
      "\n",
      "Naive Bayes Accuracy on SMOTE data: 0.6687153053132434\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Naive Bayes model on the resampled test data\n",
    "naive_bayes_accuracy_resampled = evaluate_model(naive_bayes_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"Naive Bayes Accuracy on SMOTE data: {naive_bayes_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train a Support Vector Machine (SVM) Classifier.\"\"\"\n",
    "    model = SVC(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the SVM model on resampled data\n",
    "svm_model_resampled = train_svm(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94508\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.95214   0.93913   0.94559      2563\n",
      "           1    0.93800   0.95123   0.94457      2481\n",
      "\n",
      "    accuracy                        0.94508      5044\n",
      "   macro avg    0.94507   0.94518   0.94508      5044\n",
      "weighted avg    0.94518   0.94508   0.94509      5044\n",
      "\n",
      "SVM Accuracy on SMOTE data: 0.9450832672482157\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the SVM model on the resampled test data\n",
    "svm_accuracy_resampled = evaluate_model(svm_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"SVM Accuracy on SMOTE data: {svm_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "def train_perceptron(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train a Perceptron Classifier.\"\"\"\n",
    "    model = Perceptron(random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the Perceptron model on resampled data\n",
    "perceptron_model_resampled = train_perceptron(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81582\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    0.81839   0.81935   0.81887      2563\n",
      "           1    0.81316   0.81217   0.81266      2481\n",
      "\n",
      "    accuracy                        0.81582      5044\n",
      "   macro avg    0.81578   0.81576   0.81577      5044\n",
      "weighted avg    0.81582   0.81582   0.81582      5044\n",
      "\n",
      "Perceptron Accuracy on SMOTE data: 0.8158207771609833\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Perceptron model on the resampled test data\n",
    "perceptron_accuracy_resampled = evaluate_model(perceptron_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"Perceptron Accuracy on SMOTE data: {perceptron_accuracy_resampled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train_mlp(X_train, y_train, random_state=42):\n",
    "    \"\"\"Train a Multilayer Perceptron (MLP) Classifier.\"\"\"\n",
    "    model = MLPClassifier(random_state=random_state, max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the MLP model on resampled data\n",
    "mlp_model_resampled = train_mlp(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97343\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.94772   0.97316      2563\n",
      "           1    0.94876   1.00000   0.97370      2481\n",
      "\n",
      "    accuracy                        0.97343      5044\n",
      "   macro avg    0.97438   0.97386   0.97343      5044\n",
      "weighted avg    0.97480   0.97343   0.97343      5044\n",
      "\n",
      "MLP Accuracy on SMOTE data: 0.9734337827121332\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the MLP model on the resampled test data\n",
    "mlp_accuracy_resampled = evaluate_model(mlp_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"MLP Accuracy on SMOTE data: {mlp_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    \"\"\"Train a K-Nearest Neighbors (KNN) Classifier.\"\"\"\n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train the KNN model on resampled data\n",
    "knn_model_resampled = train_knn(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76864\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   0.54467   0.70523      2563\n",
      "           1    0.68010   1.00000   0.80959      2481\n",
      "\n",
      "    accuracy                        0.76864      5044\n",
      "   macro avg    0.84005   0.77234   0.75741      5044\n",
      "weighted avg    0.84265   0.76864   0.75656      5044\n",
      "\n",
      "KNN Accuracy on SMOTE data: 0.7686360031720857\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the KNN model on the resampled test data\n",
    "knn_accuracy_resampled = evaluate_model(knn_model_resampled, X_test_resampled, y_test_resampled)\n",
    "print(f\"KNN Accuracy on SMOTE data: {knn_accuracy_resampled}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 768 features.\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of features in your dataset\n",
    "num_features = X_train_resampled.shape[1]\n",
    "print(f\"The dataset has {num_features} features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  Importance\n",
      "685      685    0.008952\n",
      "127      127    0.008950\n",
      "406      406    0.007081\n",
      "46        46    0.006471\n",
      "370      370    0.005836\n",
      "666      666    0.005742\n",
      "339      339    0.005441\n",
      "109      109    0.005380\n",
      "251      251    0.005369\n",
      "161      161    0.005004\n",
      "1          1    0.004837\n",
      "588      588    0.004222\n",
      "752      752    0.004136\n",
      "273      273    0.003823\n",
      "198      198    0.003779\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importances from the Random Forest model\n",
    "rf_feature_importances = rf_model_resampled.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_resampled.columns if hasattr(X_train_resampled, 'columns') else range(len(rf_feature_importances)),\n",
    "    \"Importance\": rf_feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "rf_importance_df = rf_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 15 features\n",
    "top_15_features_rf = rf_importance_df.head(15)\n",
    "print(top_15_features_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Feature  Importance\n",
      "131      131    0.000714\n",
      "396      396    0.000712\n",
      "519      519    0.000706\n",
      "14        14    0.000702\n",
      "136      136    0.000691\n",
      "234      234    0.000677\n",
      "292      292    0.000673\n",
      "188      188    0.000662\n",
      "537      537    0.000659\n",
      "391      391    0.000655\n",
      "552      552    0.000653\n",
      "718      718    0.000651\n",
      "84        84    0.000640\n",
      "266      266    0.000632\n",
      "282      282    0.000618\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importances from the Random Forest model\n",
    "rf_feature_importances = rf_model_resampled.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "rf_importance_df = pd.DataFrame({\n",
    "    \"Feature\": X_train_resampled.columns if hasattr(X_train_resampled, 'columns') else range(len(rf_feature_importances)),\n",
    "    \"Importance\": rf_feature_importances\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "rf_importance_df = rf_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 15 features\n",
    "top_15_features_rf = rf_importance_df.tail(15)\n",
    "print(top_15_features_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "def shap_for_tree_model(model, X_resampled):\n",
    "    \"\"\"Apply SHAP to explain tree-based models with additivity check disabled.\"\"\"\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_resampled, check_additivity=False)\n",
    "    return shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [685, 127]\n",
    "X_selected_features = X_train_resampled.iloc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single instance with selected features\n",
    "instance_selected = X_selected_features.iloc[0:1]\n",
    "\n",
    "# Compute SHAP values for the instance\n",
    "shap_values_instance = shap.TreeExplainer(rf_model_resampled).shap_values(instance_selected)\n",
    "\n",
    "# Visualize feature impact for the instance\n",
    "shap.force_plot(\n",
    "    base_value=shap.TreeExplainer(rf_model_resampled).expected_value[1],\n",
    "    shap_values=shap_values_instance[1],\n",
    "    features=instance_selected,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_for_input(prompt, answer, tokenizer, model):\n",
    "    \"\"\"Generate BERT embeddings for a single user input.\"\"\"\n",
    "    # Combine prompt and answer\n",
    "    text = f\"{prompt} [SEP] {answer}\"\n",
    "    \n",
    "    # Tokenize and encode\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    # Generate embeddings using BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    \n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_input(prompt, answer, model, tokenizer, bert_model):\n",
    "    \"\"\"Predict the label for user input using the best model.\"\"\"\n",
    "    # Generate embeddings for the input\n",
    "    user_embeddings = get_embeddings_for_input(prompt, answer, tokenizer, bert_model)\n",
    "    \n",
    "    # Reshape embeddings to match input format\n",
    "    user_embeddings = user_embeddings.reshape(1, -1)\n",
    "    \n",
    "    # Predict the label\n",
    "    prediction = model.predict(user_embeddings)\n",
    "    return prediction[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted label for the given input is: 0\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Reload BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Define the function to embed user input and predict\n",
    "def predict_user_input(prompt, answer, model, tokenizer, bert_model):\n",
    "    \"\"\"Predict the label for user-provided prompt and answer.\"\"\"\n",
    "    # Combine prompt and answer into a single string\n",
    "    combined_text = f\"{prompt} [SEP] {answer}\"\n",
    "    \n",
    "    # Tokenize and encode the input\n",
    "    inputs = tokenizer(\n",
    "        combined_text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512\n",
    "    )\n",
    "    \n",
    "    # Get embeddings from BERT\n",
    "    with torch.no_grad():\n",
    "        embeddings = bert_model(**inputs).pooler_output.numpy()\n",
    "    \n",
    "    # Predict using the provided model\n",
    "    prediction = model.predict(embeddings)\n",
    "    return prediction[0]\n",
    "\n",
    "# Example user input\n",
    "user_prompt = input(\"Enter a prompt: \")\n",
    "user_answer = input(\"Enter an answer: \")\n",
    "\n",
    "# Predict using the Random Forest model (best model in this case)\n",
    "best_prediction = predict_user_input(user_prompt, user_answer, rf_model_resampled, tokenizer, bert_model)\n",
    "\n",
    "# Output the prediction\n",
    "print(f\"The predicted label for the given input is: {best_prediction}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
